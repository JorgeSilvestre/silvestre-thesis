{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911b57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math, random, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "sys.path.append('./rtaUtils')\n",
    "\n",
    "from rtaUtils import paths, experiment, data_loading\n",
    "\n",
    "import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense, Dropout\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f3e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(1234)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f957be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.1.3 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "detailed_metrics = True\n",
    "num_prev_examples = 1\n",
    "times = (15,30,60,90,120,150) # Minutes\n",
    "\n",
    "# train_data_path = Path('../data/train/train_data_with_val')\n",
    "# test_data_path  = Path('../data/test/test_data_with_val')\n",
    "# val_data_path   = Path('../data/val/validation_data')\n",
    "# models_path     = Path('./models')\n",
    "\n",
    "# Feature selection\n",
    "### Features ##################################################################\n",
    "numeric_feat = [\n",
    "    'latitude', 'longitude', 'altitude', 'departureDelay', 'vspeed', 'speed', \n",
    "    'day_of_week', 'track', 'wind_dir_degrees', 'wind_speed_kt', \n",
    "    'visibility_statute_mi', 'max_temp', 'min_temp', 'clouds', 'hav_distance'\n",
    "]\n",
    "categoric_feat = [\n",
    "    'time_of_day', 'operator', 'aerodromeOfDeparture', 'sky_status'\n",
    "]\n",
    "objective = ['RTA']\n",
    "num_features     = len(numeric_feat+categoric_feat)\n",
    "\n",
    "encoders = joblib.load(paths.utils_path / 'encoder_19.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553ffaf",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310cc6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(\n",
    "    criterion = 'squared_error',\n",
    "    n_estimators=50,\n",
    "    n_jobs=6,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f077c490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, n_jobs=6, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, n_jobs=6, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=50, n_jobs=6, verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data_loading.load_final_data(month='20220[12345]', dataset='train', sampling = 30)\n",
    "# encoders = {}\n",
    "\n",
    "for feat in categoric_feat:\n",
    "    le = LabelEncoder().fit(train_data[feat])\n",
    "    # encoders[feat] = le\n",
    "    \n",
    "    train_data[feat] = le.transform(train_data[feat]).reshape(-1,1)\n",
    "    \n",
    "model.fit(\n",
    "    train_data[numeric_feat+categoric_feat], \n",
    "    train_data[objective].values.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd572f52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, n_jobs=6, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, n_jobs=6, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=50, n_jobs=6, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data_loading.load_final_data(month='20220[6789]', dataset='train', sampling = 30)\n",
    "# encoders = {}\n",
    "\n",
    "for feat in categoric_feat:\n",
    "    le = LabelEncoder().fit(train_data[feat])\n",
    "    # encoders[feat] = le\n",
    "    \n",
    "    train_data[feat] = le.transform(train_data[feat]).reshape(-1,1)\n",
    "    \n",
    "model.fit(\n",
    "    train_data[numeric_feat+categoric_feat], \n",
    "    train_data[objective].values.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51c9d0df",
   "metadata": {},
   "source": [
    "joblib.dump(model, paths.models_path / 'RF_50units.joblib') "
   ]
  },
  {
   "cell_type": "raw",
   "id": "145738d8",
   "metadata": {},
   "source": [
    "model = joblib.load(paths.models_path / 'RF_50units.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c00ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE val set:\t\t256.68255 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE val set:\t\t498.27843 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    4.1s finished\n"
     ]
    }
   ],
   "source": [
    "val_data   = data_loading.load_final_data(month='*', dataset='val', sampling = 30)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    val_data[feat] = le.transform(val_data[feat]).reshape(-1,1)\n",
    "\n",
    "mae = mean_absolute_error(\n",
    "        val_data[objective], \n",
    "        model.predict(val_data[numeric_feat+categoric_feat]))\n",
    "print('MAE val set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        val_data[objective], \n",
    "        model.predict(val_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE val set:\\t\\t{:.5f} segundos'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9aee2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2592/2592 - Done\r"
     ]
    }
   ],
   "source": [
    "data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(val_data.fpId.unique())\n",
    "for idx,fpId in enumerate(val_data.fpId.unique()):\n",
    "    flight = val_data[val_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in data_at_times[t].items():\n",
    "        data_at_times[t][k] = np.array(data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2a62c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "15min: 192.643s\n",
      "30min: 214.200s\n",
      "60min: 238.863s\n",
      "90min: 323.193s\n",
      "120min: 382.364s\n",
      "150min: 399.939s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(data_at_times[t]['Y'], \n",
    "                                                        model.predict(data_at_times[t]['X']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbeb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test set:\t\t256.92041 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE test set:\t\t552.01595 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "test_data   = data_loading.load_final_data(month='*', dataset='test', sampling = 30)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    test_data[feat] = le.transform(test_data[feat]).reshape(-1,1)\n",
    "\n",
    "mae = mean_absolute_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat]))\n",
    "print('MAE test set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE test set:\\t\\t{:.5f} segundos'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "969d22ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3047/3047 - Done\r"
     ]
    }
   ],
   "source": [
    "test_data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(test_data.fpId.unique())\n",
    "for idx,fpId in enumerate(test_data.fpId.unique()):\n",
    "    flight = test_data[test_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            test_data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            test_data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in test_data_at_times[t].items():\n",
    "        test_data_at_times[t][k] = np.array(test_data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a60098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "15min: 191.302s\n",
      "30min: 225.646s\n",
      "60min: 243.604s\n",
      "90min: 320.148s\n",
      "120min: 385.223s\n",
      "150min: 395.168s\n",
      "RMSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15min: 693.321s\n",
      "30min: 467.571s\n",
      "60min: 543.278s\n",
      "90min: 638.971s\n",
      "120min: 534.188s\n",
      "150min: 525.142s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(test_data_at_times[t]['Y'], \n",
    "                                                        model.predict(test_data_at_times[t]['X']))))\n",
    "print('RMSE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,math.sqrt(mean_squared_error(test_data_at_times[t]['Y'], \n",
    "                                                        model.predict(test_data_at_times[t]['X'])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de981d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3047/3047 - Done\r"
     ]
    }
   ],
   "source": [
    "distances = (25,45,60,100,125,250)\n",
    "test_data_at_distance = {x:{'X':[], 'Y':[]} for x in distances}\n",
    "    \n",
    "total_legs = len(test_data.fpId.unique())\n",
    "for idx,fpId in enumerate(test_data.fpId.unique()):\n",
    "    flight = test_data[test_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in distances:\n",
    "        f = flight[flight.hav_distance >= t]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            test_data_at_distance[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            test_data_at_distance[t]['Y'].append(f.iloc[i][objective])\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in distances:\n",
    "    for k,v in test_data_at_distance[t].items():\n",
    "        test_data_at_distance[t][k] = np.array(test_data_at_distance[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd5e2205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "25NM: 127.342s\n",
      "45NM: 173.510s\n",
      "60NM: 215.690s\n",
      "100NM: 248.065s\n",
      "125NM: 248.702s\n",
      "250NM: 218.168s\n",
      "rmse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25NM: 568.444s\n",
      "45NM: 780.658s\n",
      "60NM: 765.669s\n",
      "100NM: 544.768s\n",
      "125NM: 515.271s\n",
      "250NM: 431.925s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print('MAE')\n",
    "for t in distances:\n",
    "    print('{}NM: {:.3f}s'.format(t,mean_absolute_error(test_data_at_distance[t]['Y'], \n",
    "                                                        model.predict(test_data_at_distance[t]['X']))))\n",
    "\n",
    "print('rmse')\n",
    "for t in distances:\n",
    "    print('{}NM: {:.3f}s'.format(t,math.sqrt(mean_squared_error(test_data_at_distance[t]['Y'], \n",
    "                                                        model.predict(test_data_at_distance[t]['X'])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca5c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c9fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2189/2189 - Done\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test set:\t\t313.48904 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE test set:\t\t740.80278 segundos\n",
      "MAE\n",
      "15min: 272.066s\n",
      "30min: 275.759s\n",
      "60min: 248.115s\n",
      "90min: 336.175s\n",
      "120min: 473.826s\n",
      "150min: 464.170s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    3.2s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:409: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Future data\n",
    "test_data   = data_loading.load_final_data(month='202210', dataset='test', sampling = 30)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    test_data[feat] = le.transform(test_data[feat]).reshape(-1,1)\n",
    "\n",
    "test_data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(test_data.fpId.unique())\n",
    "for idx,fpId in enumerate(test_data.fpId.unique()):\n",
    "    flight = test_data[test_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            test_data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            test_data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in test_data_at_times[t].items():\n",
    "        test_data_at_times[t][k] = np.array(test_data_at_times[t][k])\n",
    "        \n",
    "mae = mean_absolute_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat]))\n",
    "print('MAE test set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE test set:\\t\\t{:.5f} segundos'.format(rmse))\n",
    "        \n",
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(test_data_at_times[t]['Y'], \n",
    "                                                        model.predict(test_data_at_times[t]['X']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c06ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d797ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Categorical to numerical conversion\n",
    "encoders = {}\n",
    "for feat in categoric_feat:\n",
    "    le = LabelEncoder().fit(train_data[feat])\n",
    "    encoders[feat] = le\n",
    "    \n",
    "    train_data[feat] = le.transform(train_data[feat]).reshape(-1,1)\n",
    "    \n",
    "# Normalization to [0,1] range\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(train_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "scaled_train_data = scaler.transform(train_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "# Conversion to supervised problem\n",
    "# Data formatting\n",
    "train_data['idx'] = train_data.index\n",
    "# Assumes that data are sorted by flight/leg and timestamp.\n",
    "indices_train = train_data.groupby('leg').agg(first=('idx', 'first'), last=('idx', 'last'))\n",
    "\n",
    "train_X, train_Y = [],[]\n",
    "for first, last in indices_train.values:\n",
    "    temp_x, temp_y = create_dataset(scaled_train_data[first:last,:], lookback)\n",
    "    train_X.append(temp_x)\n",
    "    train_Y.append(temp_y)\n",
    "    \n",
    "train_X = np.concatenate(train_X, axis=0)\n",
    "train_Y = np.concatenate(train_Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feat in categoric_feat:\n",
    "    val_data[feat]   = le.transform(val_data[feat]).reshape(-1,1)\n",
    "scaled_val_data = scaler.transform(val_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "# Data formatting\n",
    "val_data['idx'] = val_data.index\n",
    "indices_val = val_data.groupby('leg').agg(first=('idx', 'first'), last=('idx', 'last'))\n",
    "\n",
    "val_X, val_Y = [],[]\n",
    "for first, last in indices_val.values:\n",
    "    temp_x, temp_y = create_dataset(scaled_val_data[first:last,:], lookback)\n",
    "    val_X.append(temp_x)\n",
    "    val_Y.append(temp_y)\n",
    "\n",
    "val_X = np.concatenate(val_X, axis=0)\n",
    "val_Y = np.concatenate(val_Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029814b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/738 - Done\r"
     ]
    }
   ],
   "source": [
    "# Multiple messages\n",
    "if detailed_metrics:\n",
    "    data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "    total_legs = len(val_data.leg.unique())\n",
    "    for idx,leg in enumerate(val_data.leg.unique()):\n",
    "        flight = val_data[val_data.leg == leg]\n",
    "        if (idx+1)%25==0:\n",
    "            print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "        for t in times:\n",
    "            f = flight[flight.RTA >= t*60]\n",
    "            f = f.iloc[-lookback-num_prev_examples:]\n",
    "            \n",
    "            if len(f)<lookback+num_prev_examples: \n",
    "                continue\n",
    "            \n",
    "            scaled_times_data = scaler.transform(f[numeric_feat+categoric_feat+objective])\n",
    "            test_X, test_Y    = create_dataset(scaled_times_data, lookback)\n",
    "            for i in range(num_prev_examples):\n",
    "                data_at_times[t]['X'].append(test_X[i])\n",
    "                data_at_times[t]['Y'].append(test_Y[i])\n",
    "            \n",
    "    print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "    for t in times:\n",
    "        for k,v in data_at_times[t].items():\n",
    "            data_at_times[t][k] = np.array(data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8ad0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude \t 0.00029618901046454306\n",
      "longitude \t 0.005216288208400189\n",
      "altitude \t 0.0063576640106789055\n",
      "departureDelay \t 0.0002514266013197549\n",
      "vspeed \t 9.137399246544936e-05\n",
      "speed \t 0.0035539660724611577\n",
      "day_of_week \t 3.245619303266305e-05\n",
      "track \t 0.00013495466836408365\n",
      "wind_dir_degrees \t 0.0007883066696654517\n",
      "wind_speed_kt \t 0.00033715693151600926\n",
      "visibility_statute_mi \t 0.00011893221375816626\n",
      "max_temp \t 9.370790532208846e-05\n",
      "min_temp \t 0.00013742827328527973\n",
      "clouds \t 1.529394837541134e-05\n",
      "hav_distance \t 0.9816969655543435\n",
      "time_of_day \t 8.717761596049648e-05\n",
      "operator \t 0.0004263373690699054\n",
      "aerodromeOfDeparture \t 0.00036417242674015597\n",
      "sky_status \t 2.023347767616562e-07\n"
     ]
    }
   ],
   "source": [
    "for f,i in zip(val_data[numeric_feat+categoric_feat].columns, model.feature_importances_):\n",
    "    print(f, '\\t', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c9ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eb310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f91e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6ee15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
