{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911b57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math, random, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "sys.path.append('./rtaUtils')\n",
    "\n",
    "from rtaUtils import paths, experiment, data_loading\n",
    "\n",
    "import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense, Dropout\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f3e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(1234)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f957be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_metrics = True\n",
    "num_prev_examples = 1\n",
    "times = (120,90,60,30,15) # Minutes\n",
    "\n",
    "# train_data_path = Path('../data/train/train_data_with_val')\n",
    "# test_data_path  = Path('../data/test/test_data_with_val')\n",
    "# val_data_path   = Path('../data/val/validation_data')\n",
    "# models_path     = Path('./models')\n",
    "\n",
    "# Feature selection\n",
    "### Features ##################################################################\n",
    "numeric_feat = [\n",
    "    'latitude', 'longitude', 'altitude', 'departureDelay', 'vspeed', 'speed', \n",
    "    'day_of_week', 'track', 'wind_dir_degrees', 'wind_speed_kt', \n",
    "    'visibility_statute_mi', 'max_temp', 'min_temp', 'clouds', 'hav_distance'\n",
    "]\n",
    "categoric_feat = [\n",
    "    'time_of_day', 'operator', 'aerodromeOfDeparture', 'sky_status'\n",
    "]\n",
    "objective = ['RTA']\n",
    "num_features     = len(numeric_feat+categoric_feat)\n",
    "\n",
    "encoders = joblib.load(paths.utils_path / 'encoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553ffaf",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f077c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_loading.load_final_data(month='*', dataset='train', sampling = 60)\n",
    "# encoders = {}\n",
    "\n",
    "for feat in categoric_feat:\n",
    "    le = LabelEncoder().fit(train_data[feat])\n",
    "    # encoders[feat] = le\n",
    "    \n",
    "    train_data[feat] = le.transform(train_data[feat]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd572f52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 11.0min\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(\n",
    "    criterion = 'squared_error',\n",
    "    n_estimators=50,\n",
    "    n_jobs=2,\n",
    "    verbose=1)\n",
    "model.fit(\n",
    "    train_data[numeric_feat+categoric_feat], \n",
    "    train_data[objective].values.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d988a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, paths.models_path / 'RF_50units.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c657c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(paths.models_path / 'RF_50units.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c72bae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c00ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE val set:\t\t200.17361 segundos\n",
      "MAE val set:\t\t200.17361 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE val set:\t\t353.94125 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE val set:\t\t353.94125 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.2s finished\n"
     ]
    }
   ],
   "source": [
    "val_data   = data_loading.load_final_data(month='*', dataset='val', sampling = 60)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    val_data[feat] = le.transform(val_data[feat]).reshape(-1,1)\n",
    "\n",
    "mae = mean_absolute_error(\n",
    "        val_data[objective], \n",
    "        model.predict(val_data[numeric_feat+categoric_feat]))\n",
    "print('MAE val set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        val_data[objective], \n",
    "        model.predict(val_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE val set:\\t\\t{:.5f} segundos'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9aee2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2592/2592 - Done\r"
     ]
    }
   ],
   "source": [
    "data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(val_data.fpId.unique())\n",
    "for idx,fpId in enumerate(val_data.fpId.unique()):\n",
    "    flight = val_data[val_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in data_at_times[t].items():\n",
    "        data_at_times[t][k] = np.array(data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2a62c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "120min: 275.018s\n",
      "90min: 240.444s\n",
      "MAE\n",
      "120min: 275.018s\n",
      "90min: 240.444s\n",
      "60min: 211.393s\n",
      "60min: 211.393s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30min: 177.439s\n",
      "15min: 110.917s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30min: 177.439s\n",
      "15min: 110.917s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(data_at_times[t]['Y'], \n",
    "                                                        model.predict(data_at_times[t]['X']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebbeb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test set:\t\t190.96800 segundos\n",
      "MAE test set:\t\t190.96800 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE test set:\t\t327.94489 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE test set:\t\t327.94489 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    5.4s finished\n"
     ]
    }
   ],
   "source": [
    "test_data   = data_loading.load_final_data(month='*', dataset='test', sampling = 60)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    test_data[feat] = le.transform(test_data[feat]).reshape(-1,1)\n",
    "\n",
    "mae = mean_absolute_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat]))\n",
    "print('MAE test set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE test set:\\t\\t{:.5f} segundos'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969d22ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3047/3047 - Done\r"
     ]
    }
   ],
   "source": [
    "test_data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(test_data.fpId.unique())\n",
    "for idx,fpId in enumerate(test_data.fpId.unique()):\n",
    "    flight = test_data[test_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            test_data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            test_data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in test_data_at_times[t].items():\n",
    "        test_data_at_times[t][k] = np.array(test_data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a60098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "120min: 274.053s\n",
      "90min: 221.579s\n",
      "60min: 195.967s\n",
      "MAE\n",
      "120min: 274.053s\n",
      "90min: 221.579s\n",
      "60min: 195.967s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30min: 174.116s\n",
      "15min: 107.001s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30min: 174.116s\n",
      "15min: 107.001s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(test_data_at_times[t]['Y'], \n",
    "                                                        model.predict(test_data_at_times[t]['X']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca5c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c9fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2189/2189 - Done\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test set:\t\t235.11319 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    3.6s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE test set:\t\t426.89709 segundos\n",
      "MAE\n",
      "120min: 357.823s\n",
      "90min: 263.886s\n",
      "60min: 227.582s\n",
      "30min: 190.062s\n",
      "15min: 107.987s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Future data\n",
    "test_data   = data_loading.load_final_data(month='202210', dataset='test', sampling = 60)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    test_data[feat] = le.transform(test_data[feat]).reshape(-1,1)\n",
    "\n",
    "test_data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(test_data.fpId.unique())\n",
    "for idx,fpId in enumerate(test_data.fpId.unique()):\n",
    "    flight = test_data[test_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            test_data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            test_data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in test_data_at_times[t].items():\n",
    "        test_data_at_times[t][k] = np.array(test_data_at_times[t][k])\n",
    "        \n",
    "mae = mean_absolute_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat]))\n",
    "print('MAE test set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE test set:\\t\\t{:.5f} segundos'.format(rmse))\n",
    "        \n",
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(test_data_at_times[t]['Y'], \n",
    "                                                        model.predict(test_data_at_times[t]['X']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c06ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d797ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Categorical to numerical conversion\n",
    "encoders = {}\n",
    "for feat in categoric_feat:\n",
    "    le = LabelEncoder().fit(train_data[feat])\n",
    "    encoders[feat] = le\n",
    "    \n",
    "    train_data[feat] = le.transform(train_data[feat]).reshape(-1,1)\n",
    "    \n",
    "# Normalization to [0,1] range\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(train_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "scaled_train_data = scaler.transform(train_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "# Conversion to supervised problem\n",
    "# Data formatting\n",
    "train_data['idx'] = train_data.index\n",
    "# Assumes that data are sorted by flight/leg and timestamp.\n",
    "indices_train = train_data.groupby('leg').agg(first=('idx', 'first'), last=('idx', 'last'))\n",
    "\n",
    "train_X, train_Y = [],[]\n",
    "for first, last in indices_train.values:\n",
    "    temp_x, temp_y = create_dataset(scaled_train_data[first:last,:], lookback)\n",
    "    train_X.append(temp_x)\n",
    "    train_Y.append(temp_y)\n",
    "    \n",
    "train_X = np.concatenate(train_X, axis=0)\n",
    "train_Y = np.concatenate(train_Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feat in categoric_feat:\n",
    "    val_data[feat]   = le.transform(val_data[feat]).reshape(-1,1)\n",
    "scaled_val_data = scaler.transform(val_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "# Data formatting\n",
    "val_data['idx'] = val_data.index\n",
    "indices_val = val_data.groupby('leg').agg(first=('idx', 'first'), last=('idx', 'last'))\n",
    "\n",
    "val_X, val_Y = [],[]\n",
    "for first, last in indices_val.values:\n",
    "    temp_x, temp_y = create_dataset(scaled_val_data[first:last,:], lookback)\n",
    "    val_X.append(temp_x)\n",
    "    val_Y.append(temp_y)\n",
    "\n",
    "val_X = np.concatenate(val_X, axis=0)\n",
    "val_Y = np.concatenate(val_Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029814b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/738 - Done\r"
     ]
    }
   ],
   "source": [
    "# Multiple messages\n",
    "if detailed_metrics:\n",
    "    data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "    total_legs = len(val_data.leg.unique())\n",
    "    for idx,leg in enumerate(val_data.leg.unique()):\n",
    "        flight = val_data[val_data.leg == leg]\n",
    "        if (idx+1)%25==0:\n",
    "            print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "        for t in times:\n",
    "            f = flight[flight.RTA >= t*60]\n",
    "            f = f.iloc[-lookback-num_prev_examples:]\n",
    "            \n",
    "            if len(f)<lookback+num_prev_examples: \n",
    "                continue\n",
    "            \n",
    "            scaled_times_data = scaler.transform(f[numeric_feat+categoric_feat+objective])\n",
    "            test_X, test_Y    = create_dataset(scaled_times_data, lookback)\n",
    "            for i in range(num_prev_examples):\n",
    "                data_at_times[t]['X'].append(test_X[i])\n",
    "                data_at_times[t]['Y'].append(test_Y[i])\n",
    "            \n",
    "    print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "    for t in times:\n",
    "        for k,v in data_at_times[t].items():\n",
    "            data_at_times[t][k] = np.array(data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8ad0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude \t 0.00029618901046454306\n",
      "longitude \t 0.005216288208400189\n",
      "altitude \t 0.0063576640106789055\n",
      "departureDelay \t 0.0002514266013197549\n",
      "vspeed \t 9.137399246544936e-05\n",
      "speed \t 0.0035539660724611577\n",
      "day_of_week \t 3.245619303266305e-05\n",
      "track \t 0.00013495466836408365\n",
      "wind_dir_degrees \t 0.0007883066696654517\n",
      "wind_speed_kt \t 0.00033715693151600926\n",
      "visibility_statute_mi \t 0.00011893221375816626\n",
      "max_temp \t 9.370790532208846e-05\n",
      "min_temp \t 0.00013742827328527973\n",
      "clouds \t 1.529394837541134e-05\n",
      "hav_distance \t 0.9816969655543435\n",
      "time_of_day \t 8.717761596049648e-05\n",
      "operator \t 0.0004263373690699054\n",
      "aerodromeOfDeparture \t 0.00036417242674015597\n",
      "sky_status \t 2.023347767616562e-07\n"
     ]
    }
   ],
   "source": [
    "for f,i in zip(val_data[numeric_feat+categoric_feat].columns, model.feature_importances_):\n",
    "    print(f, '\\t', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c9ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eb310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f91e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6ee15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
