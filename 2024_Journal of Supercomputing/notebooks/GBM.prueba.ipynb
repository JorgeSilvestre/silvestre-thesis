{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911b57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math, random, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "sys.path.append('./rtaUtils')\n",
    "\n",
    "from rtaUtils import paths, experiment, data_loading\n",
    "\n",
    "import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense, Dropout\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f3e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(1234)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f957be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_metrics = True\n",
    "num_prev_examples = 1\n",
    "times = (120,90,60,30,15) # Minutes\n",
    "\n",
    "# train_data_path = Path('../data/train/train_data_with_val')\n",
    "# test_data_path  = Path('../data/test/test_data_with_val')\n",
    "# val_data_path   = Path('../data/val/validation_data')\n",
    "# models_path     = Path('./models')\n",
    "\n",
    "# Feature selection\n",
    "### Features ##################################################################\n",
    "numeric_feat = [\n",
    "    'latitude', 'longitude', 'altitude', 'departureDelay', 'vspeed', 'speed', \n",
    "    'day_of_week', 'track', 'wind_dir_degrees', 'wind_speed_kt', \n",
    "    'visibility_statute_mi', 'max_temp', 'min_temp', 'clouds', 'hav_distance'\n",
    "]\n",
    "categoric_feat = [\n",
    "    'time_of_day', 'operator', 'aerodromeOfDeparture', 'sky_status'\n",
    "]\n",
    "objective = ['RTA']\n",
    "num_features     = len(numeric_feat+categoric_feat)\n",
    "\n",
    "encoders = joblib.load(paths.utils_path / 'encoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553ffaf",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e010ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_loading.load_final_data(month='*', dataset='train', sampling = 60)\n",
    "# encoders = {}\n",
    "\n",
    "for feat in categoric_feat:\n",
    "    le = LabelEncoder().fit(train_data[feat])\n",
    "    # encoders[feat] = le\n",
    "    \n",
    "    train_data[feat] = le.transform(train_data[feat]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd572f52",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1     6403879.0923            3.71m\n",
      "         2     5246961.2691            3.54m\n",
      "         3     4304112.9623            3.43m\n",
      "         4     3535956.0829            3.33m\n",
      "         5     2911465.8951            3.23m\n",
      "         6     2400771.7866            3.14m\n",
      "         7     1986695.7070            3.07m\n",
      "         8     1648912.5288            3.00m\n",
      "         9     1373001.6784            2.94m\n",
      "        10     1149232.5932            2.86m\n",
      "        20      282083.4799            2.17m\n",
      "        30      155950.2592            1.44m\n",
      "        40      131563.7661           43.06s\n",
      "        50      123530.8240            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(n_estimators=50, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=50, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=50, verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(\n",
    "    loss = 'squared_error',\n",
    "    n_estimators=50,\n",
    "    verbose=1)\n",
    "model.fit(\n",
    "    train_data[numeric_feat+categoric_feat], \n",
    "    train_data[objective].values.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc364ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Jorge\\\\Jupyter Notebooks\\\\tesis.RTA\\\\rtaUtils\\\\..\\\\models\\\\GBM_50units.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, paths.models_path / 'GBM_50units.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e91736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(paths.models_path / 'GBM_50units.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c00ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE val set:\t\t225.98532 segundos\n",
      "RMSE val set:\t\t332.41953 segundos\n"
     ]
    }
   ],
   "source": [
    "val_data   = data_loading.load_final_data(month='*', dataset='val', sampling = 60)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    val_data[feat] = le.transform(val_data[feat]).reshape(-1,1)\n",
    "\n",
    "mae = mean_absolute_error(\n",
    "        val_data[objective], \n",
    "        model.predict(val_data[numeric_feat+categoric_feat]))\n",
    "print('MAE val set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        val_data[objective], \n",
    "        model.predict(val_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE val set:\\t\\t{:.5f} segundos'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9aee2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2592/2592 - Done\r"
     ]
    }
   ],
   "source": [
    "data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(val_data.fpId.unique())\n",
    "for idx,fpId in enumerate(val_data.fpId.unique()):\n",
    "    flight = val_data[val_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in data_at_times[t].items():\n",
    "        data_at_times[t][k] = np.array(data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2a62c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "120min: 300.801s\n",
      "90min: 250.089s\n",
      "60min: 207.354s\n",
      "30min: 188.987s\n",
      "15min: 151.970s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(data_at_times[t]['Y'], \n",
    "                                                        model.predict(data_at_times[t]['X']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebbeb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test set:\t\t223.08522 segundos\n",
      "RMSE test set:\t\t328.25483 segundos\n"
     ]
    }
   ],
   "source": [
    "test_data   = data_loading.load_final_data(month='*', dataset='test', sampling = 60)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    test_data[feat] = le.transform(test_data[feat]).reshape(-1,1)\n",
    "\n",
    "mae = mean_absolute_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat]))\n",
    "print('MAE test set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE test set:\\t\\t{:.5f} segundos'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969d22ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3047/3047 - Done\r"
     ]
    }
   ],
   "source": [
    "test_data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(test_data.fpId.unique())\n",
    "for idx,fpId in enumerate(test_data.fpId.unique()):\n",
    "    flight = test_data[test_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            test_data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            test_data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in test_data_at_times[t].items():\n",
    "        test_data_at_times[t][k] = np.array(test_data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a60098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "120min: 298.397s\n",
      "90min: 254.509s\n",
      "60min: 209.002s\n",
      "30min: 189.564s\n",
      "15min: 157.001s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(test_data_at_times[t]['Y'], \n",
    "                                                        model.predict(test_data_at_times[t]['X']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca5c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f452642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE test set:\t\t255.42247 segundos\n",
      "RMSE test set:\t\t376.62329 segundos\n",
      "MAE\n",
      "120min: 389.364s\n",
      "90min: 296.140s\n",
      "60min: 226.617s\n",
      "30min: 191.979s\n",
      "15min: 144.144s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jorge\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Future data\n",
    "test_data   = data_loading.load_final_data(month='202210', dataset='test', sampling = 60)\n",
    "for feat in categoric_feat:\n",
    "    le = encoders[feat]\n",
    "    test_data[feat] = le.transform(test_data[feat]).reshape(-1,1)\n",
    "\n",
    "test_data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "total_legs = len(test_data.fpId.unique())\n",
    "for idx,fpId in enumerate(test_data.fpId.unique()):\n",
    "    flight = test_data[test_data.fpId == fpId]\n",
    "    if (idx+1)%25==0:\n",
    "        print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "    for t in times:\n",
    "        f = flight[flight.RTA >= t*60]\n",
    "        f = f.iloc[-num_prev_examples:]\n",
    "\n",
    "        if len(f)<num_prev_examples: \n",
    "            continue\n",
    "        \n",
    "        for i in range(num_prev_examples):\n",
    "            test_data_at_times[t]['X'].append(f.iloc[i][numeric_feat+categoric_feat])\n",
    "            test_data_at_times[t]['Y'].append(f.iloc[i][objective])\n",
    "\n",
    "print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "for t in times:\n",
    "    for k,v in test_data_at_times[t].items():\n",
    "        test_data_at_times[t][k] = np.array(test_data_at_times[t][k])\n",
    "        \n",
    "mae = mean_absolute_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat]))\n",
    "print('MAE test set:\\t\\t{:.5f} segundos'.format(mae))\n",
    "\n",
    "rmse = math.sqrt(\n",
    "    mean_squared_error(\n",
    "        test_data[objective], \n",
    "        model.predict(test_data[numeric_feat+categoric_feat])))\n",
    "print('RMSE test set:\\t\\t{:.5f} segundos'.format(rmse))\n",
    "        \n",
    "print('MAE')\n",
    "for t in times:\n",
    "    print('{}min: {:.3f}s'.format(t,mean_absolute_error(test_data_at_times[t]['Y'], \n",
    "                                                        model.predict(test_data_at_times[t]['X']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005814ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806598e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78632c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Categorical to numerical conversion\n",
    "encoders = {}\n",
    "for feat in categoric_feat:\n",
    "    le = LabelEncoder().fit(train_data[feat])\n",
    "    encoders[feat] = le\n",
    "    \n",
    "    train_data[feat] = le.transform(train_data[feat]).reshape(-1,1)\n",
    "    \n",
    "# Normalization to [0,1] range\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(train_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "scaled_train_data = scaler.transform(train_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "# Conversion to supervised problem\n",
    "# Data formatting\n",
    "train_data['idx'] = train_data.index\n",
    "# Assumes that data are sorted by flight/leg and timestamp.\n",
    "indices_train = train_data.groupby('leg').agg(first=('idx', 'first'), last=('idx', 'last'))\n",
    "\n",
    "train_X, train_Y = [],[]\n",
    "for first, last in indices_train.values:\n",
    "    temp_x, temp_y = create_dataset(scaled_train_data[first:last,:], lookback)\n",
    "    train_X.append(temp_x)\n",
    "    train_Y.append(temp_y)\n",
    "    \n",
    "train_X = np.concatenate(train_X, axis=0)\n",
    "train_Y = np.concatenate(train_Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feat in categoric_feat:\n",
    "    val_data[feat]   = le.transform(val_data[feat]).reshape(-1,1)\n",
    "scaled_val_data = scaler.transform(val_data[numeric_feat+categoric_feat+objective])\n",
    "\n",
    "# Data formatting\n",
    "val_data['idx'] = val_data.index\n",
    "indices_val = val_data.groupby('leg').agg(first=('idx', 'first'), last=('idx', 'last'))\n",
    "\n",
    "val_X, val_Y = [],[]\n",
    "for first, last in indices_val.values:\n",
    "    temp_x, temp_y = create_dataset(scaled_val_data[first:last,:], lookback)\n",
    "    val_X.append(temp_x)\n",
    "    val_Y.append(temp_y)\n",
    "\n",
    "val_X = np.concatenate(val_X, axis=0)\n",
    "val_Y = np.concatenate(val_Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029814b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/738 - Done\r"
     ]
    }
   ],
   "source": [
    "# Multiple messages\n",
    "if detailed_metrics:\n",
    "    data_at_times = {x:{'X':[], 'Y':[]} for x in times}\n",
    "    \n",
    "    total_legs = len(val_data.leg.unique())\n",
    "    for idx,leg in enumerate(val_data.leg.unique()):\n",
    "        flight = val_data[val_data.leg == leg]\n",
    "        if (idx+1)%25==0:\n",
    "            print('{}/{}'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "\n",
    "        for t in times:\n",
    "            f = flight[flight.RTA >= t*60]\n",
    "            f = f.iloc[-lookback-num_prev_examples:]\n",
    "            \n",
    "            if len(f)<lookback+num_prev_examples: \n",
    "                continue\n",
    "            \n",
    "            scaled_times_data = scaler.transform(f[numeric_feat+categoric_feat+objective])\n",
    "            test_X, test_Y    = create_dataset(scaled_times_data, lookback)\n",
    "            for i in range(num_prev_examples):\n",
    "                data_at_times[t]['X'].append(test_X[i])\n",
    "                data_at_times[t]['Y'].append(test_Y[i])\n",
    "            \n",
    "    print('{}/{} - Done'.format(idx+1,total_legs).ljust(10,' '), end='\\r')\n",
    "    for t in times:\n",
    "        for k,v in data_at_times[t].items():\n",
    "            data_at_times[t][k] = np.array(data_at_times[t][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8ad0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude \t 0.00029618901046454306\n",
      "longitude \t 0.005216288208400189\n",
      "altitude \t 0.0063576640106789055\n",
      "departureDelay \t 0.0002514266013197549\n",
      "vspeed \t 9.137399246544936e-05\n",
      "speed \t 0.0035539660724611577\n",
      "day_of_week \t 3.245619303266305e-05\n",
      "track \t 0.00013495466836408365\n",
      "wind_dir_degrees \t 0.0007883066696654517\n",
      "wind_speed_kt \t 0.00033715693151600926\n",
      "visibility_statute_mi \t 0.00011893221375816626\n",
      "max_temp \t 9.370790532208846e-05\n",
      "min_temp \t 0.00013742827328527973\n",
      "clouds \t 1.529394837541134e-05\n",
      "hav_distance \t 0.9816969655543435\n",
      "time_of_day \t 8.717761596049648e-05\n",
      "operator \t 0.0004263373690699054\n",
      "aerodromeOfDeparture \t 0.00036417242674015597\n",
      "sky_status \t 2.023347767616562e-07\n"
     ]
    }
   ],
   "source": [
    "for f,i in zip(val_data[numeric_feat+categoric_feat].columns, model.feature_importances_):\n",
    "    print(f, '\\t', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c9ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eb310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f91e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6ee15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
